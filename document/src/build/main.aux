\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{Abstract{} }{3}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Abstract{} (in Finnish)}{4}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Abstract{} (in Swedish)}{5}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{Contents}{6}{section*.4}\protected@file@percent }
\citation{pinnpde}
\citation{hauptmann}
\citation{rainnet}
\citation{metnet}
\citation{deepide}
\citation{debezenac}
\citation{deepide}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{8}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Theoretical Background}{10}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Spatio-temporal Data}{10}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Defining Spatio-Temporal Data}{10}{subsubsection.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Advection-Diffusion Model}{10}{subsubsection.2.1.2}\protected@file@percent }
\newlabel{subsubsection:dynamicmodellingspatiotemporaldata}{{2.1.2}{10}{Advection-Diffusion Model}{subsubsection.2.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Advection-diffusion process with two Gaussian kernels. The objects are transported according to the velocity field and diffused outwards with a constant diffusion parameter.\relax }}{11}{figure.caption.6}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:advection_diffusion}{{2.1}{11}{Advection-diffusion process with two Gaussian kernels. The objects are transported according to the velocity field and diffused outwards with a constant diffusion parameter.\relax }{figure.caption.6}{}}
\newlabel{eq:advection}{{2.1}{11}{Advection-Diffusion Model}{equation.2.1}{}}
\newlabel{eq:diffusion}{{2.2}{11}{Advection-Diffusion Model}{equation.2.2}{}}
\newlabel{eq:advectiondiffusion}{{2.3}{11}{Advection-Diffusion Model}{equation.2.3}{}}
\newlabel{eq:advectiondiffusion_approx}{{2.4}{11}{Advection-Diffusion Model}{equation.2.4}{}}
\citation{mcculloch}
\citation{hebb}
\citation{mcculloch}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Neural Networks}{12}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Neurons and Activation Functions}{12}{subsubsection.2.2.1}\protected@file@percent }
\citation{hebb}
\citation{rosenblatt}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces McCulloch-Pitts Neuron takes a binary input vector, evaluates its sum and determines the binary output by comparing the sum to a given threshold.\relax }}{13}{figure.caption.7}\protected@file@percent }
\newlabel{fig:mccullochpittsneuron}{{2.2}{13}{McCulloch-Pitts Neuron takes a binary input vector, evaluates its sum and determines the binary output by comparing the sum to a given threshold.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Perceptron allows any input values that are weighted with $w$ and adds a bias term $\beta $. With a more sophisticated activation function $\phi $, the output values can also be anything.\relax }}{14}{figure.caption.8}\protected@file@percent }
\newlabel{fig:perceptron}{{2.3}{14}{Perceptron allows any input values that are weighted with $w$ and adds a bias term $\beta $. With a more sophisticated activation function $\phi $, the output values can also be anything.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Different commonly used activation functions in neural networks. The activation functions control the range of values going through a network, and introduce nonlinearity to the otherwise linear networks.\relax }}{14}{figure.caption.9}\protected@file@percent }
\newlabel{fig:activations}{{2.4}{14}{Different commonly used activation functions in neural networks. The activation functions control the range of values going through a network, and introduce nonlinearity to the otherwise linear networks.\relax }{figure.caption.9}{}}
\citation{cybenko}
\citation{horniketal}
\citation{hornik}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces  A schematic illustration of multiplayer perceptron. The model has one hidden layer with two perceptrons, and the output is two-dimensional. By composing multiple perceptrons together, a neural network uses more parameters to learn more complex patterns from data\relax }}{15}{figure.caption.10}\protected@file@percent }
\newlabel{fig:mlp}{{2.5}{15}{A schematic illustration of multiplayer perceptron. The model has one hidden layer with two perceptrons, and the output is two-dimensional. By composing multiple perceptrons together, a neural network uses more parameters to learn more complex patterns from data\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Convolutional Neural Networks}{15}{subsubsection.2.2.2}\protected@file@percent }
\citation{goodfellow}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Two-dimensional convolution with a $3 \times 3$ kernel. The convolution operation can be used to reduce the dimensions of the input while retaining essential features with a suitable convolution kernel.\relax }}{16}{figure.caption.11}\protected@file@percent }
\newlabel{fig:2dconv}{{2.6}{16}{Two-dimensional convolution with a $3 \times 3$ kernel. The convolution operation can be used to reduce the dimensions of the input while retaining essential features with a suitable convolution kernel.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.3}Optimising Neural Network Parameters}{17}{subsubsection.2.2.3}\protected@file@percent }
\newlabel{subsubsec:optimisation}{{2.2.3}{17}{Optimising Neural Network Parameters}{subsubsection.2.2.3}{}}
\citation{goodfellow}
\citation{goodfellow}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Stochastic gradient descent\relax }}{18}{algorithm.1}\protected@file@percent }
\newlabel{alg:sgd}{{1}{18}{Stochastic gradient descent\relax }{algorithm.1}{}}
\citation{werbos}
\citation{rumelhartetal}
\citation{linnainmaa}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.4}Backpropagation}{19}{subsubsection.2.2.4}\protected@file@percent }
\newlabel{eq:mlpchainrule}{{2.5}{20}{Backpropagation}{equation.2.5}{}}
\newlabel{eq:mlchainrulevec}{{2.6}{20}{Backpropagation}{equation.2.6}{}}
\citation{kalman}
\citation{stratonovich2}
\citation{stratonovich1}
\citation{mcgee}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Bayesian Filtering}{21}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Bayesian Inference}{21}{subsubsection.2.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Probabilistic state-space models}{21}{subsubsection.2.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Dependency scheme of the state-space model.\relax }}{22}{figure.caption.12}\protected@file@percent }
\newlabel{fig:statespacedependency}{{2.7}{22}{Dependency scheme of the state-space model.\relax }{figure.caption.12}{}}
\newlabel{eq:markov1}{{2.7}{22}{Probabilistic state-space models}{equation.2.7}{}}
\newlabel{eq:markov2}{{2.8}{22}{Probabilistic state-space models}{equation.2.8}{}}
\newlabel{def:state-space}{{2.1}{22}{Probabilistic state-space model}{definition.2.1}{}}
\newlabel{eq:statespace}{{2.9}{22}{Probabilistic state-space model}{equation.2.9}{}}
\newlabel{eq:statespace1}{{2.9b}{22}{Probabilistic state-space model}{equation.2.2}{}}
\newlabel{eq:statespace2}{{2.9c}{22}{Probabilistic state-space model}{equation.2.3}{}}
\newlabel{eq:statespacemodel}{{2.10}{22}{Probabilistic state-space models}{equation.2.10}{}}
\newlabel{eq:statespacemodel1}{{2.10a}{22}{Probabilistic state-space models}{equation.2.1}{}}
\newlabel{eq:statespacemodel2}{{2.10b}{22}{Probabilistic state-space models}{equation.2.2}{}}
\newlabel{thm:updateformulas}{{2.2}{23}{Bayesian filtering equations}{theorem.2.2}{}}
\newlabel{eq:predictionstep}{{2.11}{23}{Bayesian filtering equations}{equation.2.11}{}}
\newlabel{eq:updatestep}{{2.12}{23}{Bayesian filtering equations}{equation.2.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Kalman Filter}{24}{subsubsection.2.3.3}\protected@file@percent }
\newlabel{eq:kalmanstatespace}{{2.13}{24}{Kalman Filter}{equation.2.13}{}}
\newlabel{thm:kalmanfilterupdate}{{2.3}{24}{Kalman filter equations}{theorem.2.3}{}}
\newlabel{eq:kalmanpredictionstep}{{2.14}{24}{Kalman filter equations}{equation.2.14}{}}
\newlabel{eq:kalmanupdatestep}{{2.15}{24}{Kalman filter equations}{equation.2.15}{}}
\newlabel{eq:kalmanposteriorcov}{{2.15e}{24}{Kalman filter equations}{equation.2.5}{}}
\citation{evensen1994}
\citation{enkfbook}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4}Ensemble Kalman Filter}{25}{subsubsection.2.3.4}\protected@file@percent }
\newlabel{eq:enkalmanstochasticupdatestep}{{2.17}{26}{Ensemble Kalman Filter}{equation.2.17}{}}
\newlabel{lemma:woodbury}{{2.1}{26}{Woodbury matrix identity}{lemma.2.1}{}}
\newlabel{alg:etkf}{{2}{27}{Ensemble transform Kalman filter (ETKF)\relax }{algorithm.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Ensemble transform Kalman filter (ETKF)\relax }}{27}{algorithm.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Model}{29}{section.3}\protected@file@percent }
\newlabel{subsec:nnmodel}{{3.1}{29}{Deterministic Neural Network Model}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Deterministic Neural Network Model}{29}{subsection.3.1}\protected@file@percent }
\newlabel{eq:warping}{{3.1}{29}{Deterministic Neural Network Model}{equation.3.1}{}}
\citation{pulkkinenetal}
\citation{kitti}
\citation{sintel}
\citation{debezenac}
\citation{deepide}
\citation{debezenac}
\citation{deepide}
\citation{deepide}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The warping operator takes the pixel values and moves them to new pixels corresponding to the velocity field. The velocity field moves pixel values one step up and one to the right at each time step.\relax }}{30}{figure.caption.13}\protected@file@percent }
\newlabel{fig:warping}{{3.1}{30}{The warping operator takes the pixel values and moves them to new pixels corresponding to the velocity field. The velocity field moves pixel values one step up and one to the right at each time step.\relax }{figure.caption.13}{}}
\citation{resnet}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Model Architecture}{31}{subsubsection.3.1.1}\protected@file@percent }
\newlabel{eq:residualblock}{{3.2}{31}{Model Architecture}{equation.3.2}{}}
\newlabel{eq:residualblockderivative}{{3.3}{31}{Model Architecture}{equation.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The structure of the used 26-layer ResNet architecture. The network takes as an input spatio-temporal data with temporal dimension $t$, and spatial dimension $n \times n$, and outputs a vector of length $n_{\text  {basis}}$. Here, the residual blocks that sum the block input to its output are the groups of layers in the brackets. The layer parameters are the used kernel size, followed by the layer type, number of output channels, and stride. Striding divides the spatial dimension by the used parameter by skipping that number of pixels when computing the results. The maxpool layer outputs the maximum value inside the used kernel size, and the average pool takes the average value. In the last layers, the adaptive average pool adjusts the kernel size such that the output shape of the layer is $512 \times 1 \times 1$, and the linear layer is just a matrix multiplication to produce an $n_{\text  {basis}}$-vector. \relax }}{32}{figure.caption.14}\protected@file@percent }
\newlabel{fig:resnetmodel}{{3.2}{32}{The structure of the used 26-layer ResNet architecture. The network takes as an input spatio-temporal data with temporal dimension $t$, and spatial dimension $n \times n$, and outputs a vector of length $n_{\text {basis}}$. Here, the residual blocks that sum the block input to its output are the groups of layers in the brackets. The layer parameters are the used kernel size, followed by the layer type, number of output channels, and stride. Striding divides the spatial dimension by the used parameter by skipping that number of pixels when computing the results. The maxpool layer outputs the maximum value inside the used kernel size, and the average pool takes the average value. In the last layers, the adaptive average pool adjusts the kernel size such that the output shape of the layer is $512 \times 1 \times 1$, and the linear layer is just a matrix multiplication to produce an $n_{\text {basis}}$-vector. \relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Producing Vector Fields and Forecasts}{33}{subsubsection.3.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The six nodes at which the neural network approximates velocity fields. In order to ensure stable invertibility of the two-dimensional Vandermonde matrix, the location of the nodes must be selected carefully.\relax }}{34}{figure.caption.15}\protected@file@percent }
\newlabel{fig:testpoints}{{3.3}{34}{The six nodes at which the neural network approximates velocity fields. In order to ensure stable invertibility of the two-dimensional Vandermonde matrix, the location of the nodes must be selected carefully.\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}Training the Neural Network}{34}{subsubsection.3.1.3}\protected@file@percent }
\citation{deepide}
\newlabel{subsec:etkfmodel}{{3.2}{35}{Integrating the Neural Network into ETKF}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Integrating the Neural Network into ETKF}{35}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}State-Space Model Operators}{36}{subsubsection.3.2.1}\protected@file@percent }
\newlabel{subsubsec:etkftuning}{{3.2.2}{36}{ETKF settings}{subsubsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}ETKF settings}{36}{subsubsection.3.2.2}\protected@file@percent }
\citation{liou}
\citation{nwcsaf}
\citation{cot}
\@writefile{toc}{\contentsline {section}{\numberline {4}Numerical Experiments}{38}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Cloud Optical Thickness Data}{38}{subsection.4.1}\protected@file@percent }
\citation{pyresample}
\citation{nwcsaf}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}COT Data Preprocessing}{39}{subsubsection.4.1.1}\protected@file@percent }
\newlabel{subsec:cotpreprocessing}{{4.1.1}{39}{COT Data Preprocessing}{subsubsection.4.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces The area selected for neural network training over southern Finland and the Gulf of Finland. The entire image area is $512 \times 512$ pixels from which four $128 \times 128$ sub-images were taken. One pixel covers roughly \SI {2}{\kilo \metre } in longitude and \SI {1}{\kilo \metre } in latitude. The missing measurements, represented as black pixels, present a major complication in satellite data usage.\relax }}{39}{figure.caption.16}\protected@file@percent }
\newlabel{fig:trainingdata_area}{{4.1}{39}{The area selected for neural network training over southern Finland and the Gulf of Finland. The entire image area is $512 \times 512$ pixels from which four $128 \times 128$ sub-images were taken. One pixel covers roughly \SI {2}{\kilo \metre } in longitude and \SI {1}{\kilo \metre } in latitude. The missing measurements, represented as black pixels, present a major complication in satellite data usage.\relax }{figure.caption.16}{}}
\citation{ssim}
\citation{debezenac}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Neural Network Model with COT Data}{40}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.1}Tuning the Neural Network With COT Data}{40}{subsubsection.4.2.1}\protected@file@percent }
\citation{lucaskanade}
\citation{pyramidallk}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.2.2}Training Results}{41}{subsubsection.4.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Predictions for simulated synthetic data using the neural network trained with the COT dataset. The first rows show the actual data, and the second rows predicted velocity fields and images for two time steps. \relax }}{42}{figure.caption.17}\protected@file@percent }
\newlabel{fig:synthetic_example}{{4.2}{42}{Predictions for simulated synthetic data using the neural network trained with the COT dataset. The first rows show the actual data, and the second rows predicted velocity fields and images for two time steps. \relax }{figure.caption.17}{}}
\citation{fss}
\citation{fss}
\newlabel{eq:binaryfields}{{4.1}{43}{Training Results}{equation.4.1}{}}
\newlabel{eq:fssdensities}{{4.2}{43}{Training Results}{equation.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Mean absolute error (MAE) of predictions over two hours. Lower value indicates better performance. The Lucas-Kanade and neural network predictions have similar MAE values and naive higher errors.\relax }}{45}{figure.caption.18}\protected@file@percent }
\newlabel{fig:mae_loss}{{4.3}{45}{Mean absolute error (MAE) of predictions over two hours. Lower value indicates better performance. The Lucas-Kanade and neural network predictions have similar MAE values and naive higher errors.\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Root mean squared error (RMSE) of predictions over two hours. Lower RMSE value indicates better performance. The Lucas-Kanade and neural network have comparable RMSE values and naive worse values.\relax }}{45}{figure.caption.19}\protected@file@percent }
\newlabel{fig:rmse_loss}{{4.4}{45}{Root mean squared error (RMSE) of predictions over two hours. Lower RMSE value indicates better performance. The Lucas-Kanade and neural network have comparable RMSE values and naive worse values.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Fractions skill score (FSS) of predictions over two hours with two different window sizes and threshold settings. Higher value indicates better performance. The Lucas-Kanade and the neural network have similar skill while naive is worse.\relax }}{46}{figure.caption.20}\protected@file@percent }
\newlabel{fig:fss}{{4.5}{46}{Fractions skill score (FSS) of predictions over two hours with two different window sizes and threshold settings. Higher value indicates better performance. The Lucas-Kanade and the neural network have similar skill while naive is worse.\relax }{figure.caption.20}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Bayesian Filtering Results}{46}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces ETKF model example with synthetic data. The second row represents the observed data with a vertical black block of missing values, and the first row has the ensemble means of the estimated filtering distribution with the predicted velocity fields.\relax }}{47}{figure.caption.21}\protected@file@percent }
\newlabel{fig:etkfexamplesynthetic}{{4.6}{47}{ETKF model example with synthetic data. The second row represents the observed data with a vertical black block of missing values, and the first row has the ensemble means of the estimated filtering distribution with the predicted velocity fields.\relax }{figure.caption.21}{}}
\citation{intraday}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces A comparison of different model operators for the ETKF\spacefactor \@m {}. The leftmost column contains the observations with a vertical black block of simulated missing observations; the second column contains the filtering distribution with the neural network as the model operator, the third column with the Lucas-Kanade method, and the third with a trivial identity operator. Estimated velocity fields using the corresponding models in the filtered images show similar patterns with the Lucas-Kanade method and the neural network model.\relax }}{49}{figure.caption.22}\protected@file@percent }
\newlabel{fig:etkfexamplecot}{{4.7}{49}{A comparison of different model operators for the ETKF\@. The leftmost column contains the observations with a vertical black block of simulated missing observations; the second column contains the filtering distribution with the neural network as the model operator, the third column with the Lucas-Kanade method, and the third with a trivial identity operator. Estimated velocity fields using the corresponding models in the filtered images show similar patterns with the Lucas-Kanade method and the neural network model.\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Mean uncertainty estimates of the neural network computed prior forecast, observations, and posterior estimates given by the ETKF of the example in Figure~\ref  {fig:etkfexamplecot}. The error bar widths correspond to two times the spatial mean of the standard deviations. For the observation, the standard deviation was assumed to be 0.23.\relax }}{50}{figure.caption.23}\protected@file@percent }
\newlabel{fig:etkferrorbars}{{4.8}{50}{Mean uncertainty estimates of the neural network computed prior forecast, observations, and posterior estimates given by the ETKF of the example in Figure~\ref {fig:etkfexamplecot}. The error bar widths correspond to two times the spatial mean of the standard deviations. For the observation, the standard deviation was assumed to be 0.23.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Two standard deviations of the neural network ETKF model of the images in Figure~\ref  {fig:etkfexamplecot}. Missing observations lead to higher uncertainty, and also, due to the use of inflation techniques, uncertainty is larger in the areas with more clouds.\relax }}{50}{figure.caption.24}\protected@file@percent }
\newlabel{fig:etkfstd}{{4.9}{50}{Two standard deviations of the neural network ETKF model of the images in Figure~\ref {fig:etkfexamplecot}. Missing observations lead to higher uncertainty, and also, due to the use of inflation techniques, uncertainty is larger in the areas with more clouds.\relax }{figure.caption.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Concluding Remarks}{51}{section.5}\protected@file@percent }
\setcounter{NMainTxtPages}{53-1}
\citation{kaipiosomersalo}
\citation{sarkka}
\@writefile{toc}{\contentsline {section}{\numberline {A}Proofs}{53}{appendix.A}\protected@file@percent }
\newlabel{app:proofs}{{A}{53}{Proofs}{appendix.A}{}}
\newlabel{eq:updateformulas_star}{{{\textasteriskcentered }}{53}{Proofs}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Code Availability}{55}{appendix.B}\protected@file@percent }
\bibstyle{plain}
\bibdata{references}
\bibcite{enkfbook}{1}
\bibcite{rainnet}{2}
\bibcite{pinnpde}{3}
\bibcite{pyramidallk}{4}
\bibcite{sintel}{5}
\bibcite{intraday}{6}
\bibcite{cybenko}{7}
\bibcite{debezenac}{8}
\bibcite{nwcsaf}{9}
\bibcite{evensen1994}{10}
\bibcite{kitti}{11}
\bibcite{goodfellow}{12}
\bibcite{resnet}{13}
\bibcite{hebb}{14}
\bibcite{pyresample}{15}
\bibcite{hornik}{16}
\bibcite{horniketal}{17}
\bibcite{kaipiosomersalo}{18}
\bibcite{kalman}{19}
\bibcite{linnainmaa}{20}
\bibcite{liou}{21}
\bibcite{mcculloch}{22}
\bibcite{mcgee}{23}
\bibcite{hauptmann}{24}
\bibcite{cot}{25}
\bibcite{pulkkinenetal}{26}
\bibcite{lucaskanade}{27}
\bibcite{fss}{28}
\bibcite{rosenblatt}{29}
\bibcite{rumelhartetal}{30}
\bibcite{metnet}{31}
\bibcite{stratonovich2}{32}
\bibcite{stratonovich1}{33}
\bibcite{sarkka}{34}
\bibcite{ssim}{35}
\bibcite{werbos}{36}
\bibcite{deepide}{37}
\setcounter{NAllPages}{58}
\gdef \@abspage@last{58}
